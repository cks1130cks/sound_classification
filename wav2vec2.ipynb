{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"AtfkiKEFrI94"},"outputs":[],"source":["import os\n","import torch\n","import librosa\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import Wav2Vec2Model, Wav2Vec2Processor\n","from tqdm.notebook import tqdm\n","import numpy as np\n","import numpy as np\n","import time  # 시간 측정을 위해 time 라이브러리 추가\n","# 장치 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 모델 및 프로세서 로드\n","model_name = \"facebook/wav2vec2-large-960h-lv60-self\"\n","processor = Wav2Vec2Processor.from_pretrained(model_name)\n","model = Wav2Vec2Model.from_pretrained(model_name, torch_dtype=torch.float16).to(device)\n","\n","\n","\n","\n","def low_pass_filter(audio, sr, cutoff=2000):\n","    # FFT를 통한 주파수 도메인 변환\n","    audio_fft = np.fft.rfft(audio)\n","    frequencies = np.fft.rfftfreq(len(audio), 1/sr)\n","\n","    # 주파수가 cutoff 이상인 곳은 필터링\n","    audio_fft[frequencies > cutoff] = 0\n","\n","    # 역 FFT를 통해 시간 도메인으로 변환\n","    filtered_audio = np.fft.irfft(audio_fft)\n","    return filtered_audio\n","\n","class AudioDataset(Dataset):\n","    def __init__(self, directory, processor, sr=16000, target_length=16000*2):\n","        self.directory = directory\n","        self.processor = processor\n","        self.sr = sr\n","        self.target_length = target_length\n","        self.audio_labels = []\n","        self.audio_data = []\n","\n","        folder_list = os.listdir(directory)\n","        for label in tqdm(folder_list, desc=\"Processing folders\", leave=True):\n","            label_dir = os.path.join(directory, label)\n","            if os.path.isdir(label_dir):\n","                file_list = os.listdir(label_dir)\n","                for filename in tqdm(file_list, desc=f\"Loading files in {label}\", leave=False, mininterval=1):\n","                    if filename.endswith('.mp3') or filename.endswith('.wav'):\n","                        file_path = os.path.join(label_dir, filename)\n","                        audio, _ = librosa.load(file_path, sr=sr)\n","                        filtered_audio = low_pass_filter(audio, sr)  # 필터 적용\n","\n","                        # 지정된 길이로 오디오를 패딩하거나 자름\n","                        if len(filtered_audio) < target_length:\n","                            padding = target_length - len(filtered_audio)\n","                            filtered_audio = np.pad(filtered_audio, (0, padding), mode='constant')\n","\n","                        self.audio_data.append(filtered_audio)\n","                        self.audio_labels.append(label)\n","\n","        self.label_to_index = {label: idx for idx, label in enumerate(sorted(set(self.audio_labels)))}\n","        self.indexed_labels = [self.label_to_index[label] for label in self.audio_labels]\n","\n","    def __len__(self):\n","        return len(self.audio_data)\n","\n","    def __getitem__(self, idx):\n","        try:\n","            audio = self.audio_data[idx]\n","            label = self.indexed_labels[idx]\n","            # 모델 입력 준비\n","            inputs = self.processor(audio, sampling_rate=self.sr, return_tensors=\"pt\", padding=True).input_values.squeeze(0)\n","            return inputs, torch.tensor(label)\n","        except Exception as e:\n","            print(f\"An error occurred at index {idx}: {e}\")\n","            return None  # 대신 오류 발생시 None을 반환하지 않고 기본 값 설정을 고려\n","\n","# 분류기 정의\n","class AudioClassifier(torch.nn.Module):\n","    def __init__(self, feature_dim, num_classes):\n","        super(AudioClassifier, self).__init__()\n","        self.fc = torch.nn.Linear(feature_dim, num_classes)\n","\n","    def forward(self, x):\n","        x = self.fc(x)\n","        return x\n"]},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","# ZIP 파일 경로 설정\n","zip_file_path = '/content/drive/MyDrive/sound.zip'\n","unzip_dir = '/content/'\n","\n","# 압축을 풀 디렉토리 생성\n","os.makedirs(unzip_dir, exist_ok=True)\n","\n","# ZIP 파일 열기 및 압축 풀기\n","with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","    zip_ref.extractall(unzip_dir)\n","\n","print(f'ZIP 파일이 {unzip_dir}에 성공적으로 풀렸습니다.')\n","\n"],"metadata":{"id":"ZjyAjJmEn2U3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터셋 준비 및 데이터 로더 구성\n","dataset_directory = '/content/sound'  # 데이터셋 폴더 경로\n","dataset = AudioDataset(dataset_directory, processor)"],"metadata":{"id":"gv_WOrMpn4O9"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2381NbqWsPPn"},"outputs":[],"source":["# 새 클래스 수에 맞추어 분류기 재정의\n","num_new_classes = 2  # 새로운 클래스 수\n","classifier = AudioClassifier(1024, num_new_classes).to(device)\n","\n","# 손실 함수 및 옵티마이저\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n","\n","\n","# 학습 루프\n","def train(model, classifier, processor, device, dataloader, criterion, optimizer, epochs=100):\n","    model.eval()  # Wav2Vec2 모델은 피처 추출용이므로 eval 모드 유지\n","    classifier.train()  # 분류기는 학습 모드\n","\n","    for epoch in range(epochs):\n","        for batch_idx, (inputs, labels) in enumerate(dataloader):\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            with torch.no_grad():\n","                features = model(inputs.half()).last_hidden_state\n","\n","            logits = classifier(features.mean(dim=1).float())\n","            loss = criterion(logits, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if batch_idx % 100 == 0:\n","                print(f\"Epoch: {epoch+1}, Batch: {batch_idx}, Loss: {loss.item()}\")\n","\n","dataloader = DataLoader(dataset, batch_size=200, shuffle=True)\n","# 학습 시작\n","train(model, classifier, processor, device, dataloader, criterion, optimizer)\n","\n","print(\"Training complete\")\n","\n","# 모델 저장 경로 설정\n","save_path = '/content/drive/MyDrive/audio_classifier.pth'# 모델의 state_dict를 저장\n","torch.save(classifier.state_dict(), save_path)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"mount_file_id":"1lhh40UNBINkpMoAjhyzRb8S7Xp1PP3fD","authorship_tag":"ABX9TyPgvWx4ngEe2dTZuyHN4SRO"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}